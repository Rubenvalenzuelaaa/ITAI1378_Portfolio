# -*- coding: utf-8 -*-
"""ITIA_1378_Midterm_2024-1 (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VUT1yKy8usSp2ghO9dlyFk5c1M55PelX

#Computer Vision Midterm Assignment
## Introduction
Welcome to your Computer Vision midterm project! Here, you'll get hands-on experience building an image recognition model using Convolutional Neural Networks and transfer learning.

##Install Necessary Libraries:
"""

!pip install tensorflow
!pip install keras
!pip install numpy
!pip install matplotlib

# ==================================================
# Install Necessary Libraries (opcional si tu entorno ya las tiene)
# ==================================================
!pip install tensorflow
!pip install numpy
!pip install matplotlib

# ==================================================
# Imports
# ==================================================
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

# Reemplazamos 'keras' por 'tensorflow.keras'
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import ModelCheckpoint

# (Opcional) Si deseas usar un modelo pre-entrenado
from tensorflow.keras.applications import MobileNetV2

# ==================================================
# Additional libraries for data loading
# (if using a custom dataset)
# ==================================================
import os
import zipfile

# ==================================================
# Ejemplo de verificación de versión de TensorFlow
# ==================================================
print("TensorFlow version:", tf.__version__)

# ==================================================
# A partir de aquí, iría tu código para cargar datos,
# entrenar el modelo, etc.
# ==================================================

"""**Dataset Selection and Loading**

* **Choose Your Dataset**
   * **Standard Datasets:** CIFAR-10, CIFAR-100, or a suitable subset of ImageNet are good starting points. You can use built-in functions to load them.
   * **Custom Dataset:** If you propose a custom dataset, ensure it has sufficient images per class, good quality, and accurate labeling. You'll need to upload it to Colab.
   * **Select your dataset and uncomment the appropriate loading code.**
   * **If you are using a custom dataset, make sure you have uploaded it to Colab and adjust the file path.**
"""



# select your dataset
# from keras.datasets import cifar10 # Or cifar100, or a suitable ImageNet loader


# *** Dataset Loading - Uncomment the lines for your chosen dataset ***

# Option 1: CIFAR-10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Option 2: CIFAR-100
# (x_train, y_train), (x_test, y_test) = cifar100.load_data()

# Option 3: Custom Dataset
# x_train, y_train = load_custom_data('path/to/your/training/data')
# x_test, y_test = load_custom_data('path/to/your/testing/data')

# =========================================
# 1) Cargar CIFAR-10
# =========================================
from tensorflow.keras.datasets import cifar10

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

print("x_train shape:", x_train.shape)
print("y_train shape:", y_train.shape)
print("x_test shape:", x_test.shape)
print("y_test shape:", y_test.shape)

# =========================================
# 2) Normalizar los datos
# =========================================
x_train = x_train.astype('float32') / 255.0
x_test  = x_test.astype('float32') / 255.0

print("Data normalization done!")

# (Opcional) Convertir etiquetas a one-hot encoding para clasificación
from tensorflow.keras.utils import to_categorical

y_train = to_categorical(y_train, 10)
y_test  = to_categorical(y_test, 10)

print("Dataset loaded and ready for training!")

"""**Markdown Cell: Exploratory Data Analysis (EDA)**

* **Instructions:**
    * Visualize a few random images from your dataset to understand its content and overall quality.
    * Check the shape of your data to confirm the number of images and their dimensions.
"""

# Insert codode here
# Insert code here to display a few sample images from the dataset
## Display sample images
plt.figure(figsize=(10, 5))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(x_train[i])
plt.show()
#
print('Training data shape:', x_train.shape)
print('Training labels shape:', y_train.shape)
print('Test data shape:', x_test.shape)
print('Test labels shape:', y_test.shape)

# Explore class distribution (if using a standard dataset)
from collections import Counter
print('Class Distribution (Top 10):')
print(Counter(np.argmax(y_train, axis=1)).most_common(10))

"""**Image Preprocessing**

* **Instructions:**
    1. **Normalization:**
       * Normalize pixel values (usually to the range of 0-1 or -1 to 1)  
    2. **Resizing:**
       * Resize images to a consistent size for model input.
"""

# Insert code here to normalize images
# Normalize the data
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Resize images if needed (adjust input_shape in model building accordingly)
# x_train = tf.image.resize(x_train, (224, 224))  # Example for resizing to 224x224
# x_test = tf.image.resize(x_test, (224, 224))

# Insert code here to resize images, if needed

"""# ** Data Augmentation **

* **Instructions:**

1. Experiment with Parameters:  The code below has some example data augmentation parameters. Try changing the values within these parameters, or even adding new augmentation techniques! Here's a short guide:

* Hint 1: Start with small adjustments to see the effects clearly.
* Hint 2: Consider which augmentations make sense for your dataset. Flipping images of letters might be okay, but rotating them too much could make them unreadable!

* Explore more: Try adding things like shear_range (for shearing transformations) or zoom_range (for random zooming).

2. Visualize the Effects: After setting up your ImageDataGenerator, add a few lines of code to display some randomly augmented images from your dataset. This will help you see how your chosen parameters change the images.
* Hint: Use a small sample of images so it's easy to compare the originals with the augmented versions.
"""

train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)
train_datagen.fit(x_train)

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Data Augmentation with example parameters
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

# Make sure to call fit() if using featurewise stats
train_datagen.fit(x_train)

# Select 5 random images from the training set
num_samples = 5
indices = np.random.choice(len(x_train), num_samples)
sample_images = x_train[indices] # Define sample_images here

# Generate a batch with augmentations
augmented_images = next(train_datagen.flow(sample_images, batch_size=num_samples))

# Check if they have the expected shape and values
print("sample_images shape:", sample_images.shape)
print("sample_images min:", sample_images.min(), "max:", sample_images.max())
print("augmented_images shape:", augmented_images.shape)
print("augmented_images min:", augmented_images.min(), "max:", augmented_images.max())

# Visualize in 2 rows: row 1 (original), row 2 (augmented)
fig, axs = plt.subplots(2, num_samples, figsize=(12, 5))
for i in range(num_samples):
    axs[0, i].imshow(sample_images[i])
    axs[0, i].axis('off')
    axs[0, i].set_title("Original")

    axs[1, i].imshow(augmented_images[i])
    axs[1, i].axis('off')  # Turn off axes for the augmented images
    axs[1, i].set_title("Augmented")

plt.tight_layout()
plt.show()


print("sample_images[0][0][0] =", sample_images[0][0][0])
print("sample_images[0][16][16] =", sample_images[0][16][16])

"""#Model Building (Transfer Learning)"""

# ==========================================
# Imports
# ==========================================
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.models import Model

# Si usarás preprocesamiento especial de VGG16:
from tensorflow.keras.applications.vgg16 import preprocess_input

# Número de clases de CIFAR-10 (o las que tengas en tu dataset)
num_classes = 10

# Cargamos la base de VGG16 con pesos de ImageNet, sin la parte fully-connected
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Congelamos todas las capas del modelo base para no reentrenarlas
for layer in base_model.layers:
    layer.trainable = False

# Añadimos nuestras capas "top"
x = Flatten()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)  # opcional, para regularizar
predictions = Dense(num_classes, activation='softmax')(x)

# Construimos el modelo final
model = Model(inputs=base_model.input, outputs=predictions)

# Compilamos
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()

"""# Model Training



"""

# ==========================================
# 1) IMPORTS
# ==========================================
import numpy as np
import cv2
import tensorflow as tf

from tensorflow.keras.datasets import cifar10
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical

print("TensorFlow version:", tf.__version__)

# ==========================================
# 2) CARGAR CIFAR-10 Y REDUCIRLO
# ==========================================
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Tomamos un subconjunto para ahorrar RAM
# e.g. 5k de train y 1k de test
x_train = x_train[:5000]
y_train = y_train[:5000]
x_test  = x_test[:1000]
y_test  = y_test[:1000]

print("x_train shape (subsample):", x_train.shape)
print("y_train shape (subsample):", y_train.shape)
print("x_test shape (subsample):", x_test.shape)
print("y_test shape (subsample):", y_test.shape)

# Convertimos a float
x_train = x_train.astype('float32')
x_test  = x_test.astype('float32')

# One-hot para las etiquetas
num_classes = 10
y_train = to_categorical(y_train, num_classes)
y_test  = to_categorical(y_test, num_classes)

# ==========================================
# 3) REDIMENSIONAR A (64, 64)
# ==========================================
def resize_images(images, size=(64,64)):
    resized = []
    for img in images:
        r_img = cv2.resize(img, size)
        resized.append(r_img)
    return np.array(resized)

x_train_resized = resize_images(x_train, (64,64))
x_test_resized  = resize_images(x_test, (64,64))

print("x_train_resized shape:", x_train_resized.shape)
print("x_test_resized shape:", x_test_resized.shape)

# ==========================================
# 4) PREPROCESAR PARA MobileNetV2
# ==========================================
x_train_resized = preprocess_input(x_train_resized)
x_test_resized  = preprocess_input(x_test_resized)

# ==========================================
# 5) DEFINIR MobileNetV2 con alpha reducido
# ==========================================
# alpha < 1.0 => modelo más ligero
base_model = MobileNetV2(
    weights='imagenet',
    include_top=False,
    input_shape=(64,64,3),
    alpha=0.35  # reduce el número de filtros, ahorrando RAM
)

for layer in base_model.layers:
    layer.trainable = False

# Añadimos capas densas
from tensorflow.keras.layers import GlobalAveragePooling2D
x = GlobalAveragePooling2D()(base_model.output)  # en vez de Flatten para menor RAM
x = Dense(64, activation='relu')(x)
x = Dropout(0.5)(x)
preds = Dense(num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=preds)
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()

# ==========================================
# 6) ENTRENAMIENTO
# ==========================================
epochs = 3
batch_size = 16

history = model.fit(
    x_train_resized, y_train,
    validation_data=(x_test_resized, y_test),
    epochs=epochs,
    batch_size=batch_size
)

# ==========================================
# 7) EVALUACIÓN
# ==========================================
loss, acc = model.evaluate(x_test_resized, y_test, batch_size=batch_size)
print(f"\nTest Loss: {loss:.4f}")
print(f"Test Accuracy: {acc:.4f}")

"""#Enhanced Training

Implement data augmentation within the training loop.
Add callbacks to monitor progress and save the best performing model.
Modify the Training Code: If you haven't already, we need to make a few changes to your training loop:

1.   Integrate the Data Augmentation: Replace the
direct use of x_train with datagen.flow(x_train, y_train, batch_size=32). This will apply your augmentations in real-time during training
2.   Use the Validation Set: We already have validation_data=(x_test, y_test).
3. Save the Best Model: We're using a ModelCheckpoint callback to automatically save the model if its performance on the validation set improves
* Hint: Experiment with different batch sizes as well.
"""

!pip install matplotlib-venn

!apt-get -qq install -y libfluidsynth1

# https://pypi.python.org/pypi/libarchive
!apt-get -qq install -y libarchive-dev && pip install -U libarchive
import libarchive

!pip install cartopy
import cartopy

# =============================================
# 1) IMPORTS
# =============================================
import numpy as np
import cv2
import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint

print("TensorFlow version:", tf.__version__)

# =============================================
# 2) CARGAR CIFAR-10 Y REDUCIRLO
# (para no agotar RAM en Colab Free)
# =============================================
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Subconjunto pequeño para evitar out-of-RAM
x_train = x_train[:5000]
y_train = y_train[:5000]
x_test  = x_test[:1000]
y_test  = y_test[:1000]

print("x_train shape (subsample):", x_train.shape)
print("y_train shape (subsample):", y_train.shape)
print("x_test shape (subsample):", x_test.shape)
print("y_test shape (subsample):", y_test.shape)

# Convertir a float
x_train = x_train.astype('float32')
x_test  = x_test.astype('float32')

# One-hot para las etiquetas
num_classes = 10
y_train = to_categorical(y_train, num_classes)
y_test  = to_categorical(y_test, num_classes)

# =============================================
# 3) REDIMENSIONAR A (64, 64)
# =============================================
def resize_images(images, size=(64,64)):
    resized = []
    for img in images:
        r_img = cv2.resize(img, size)
        resized.append(r_img)
    return np.array(resized)

x_train_resized = resize_images(x_train, (64,64))
x_test_resized  = resize_images(x_test, (64,64))

print("x_train_resized shape:", x_train_resized.shape)
print("x_test_resized shape:", x_test_resized.shape)

# =============================================
# 4) PREPROCESAR (MobileNetV2)
# =============================================
x_train_resized = preprocess_input(x_train_resized)
x_test_resized  = preprocess_input(x_test_resized)

# =============================================
# 5) DEFINIR MODELO MobileNetV2 (alpha reducido)
# =============================================
base_model = MobileNetV2(
    weights='imagenet',
    include_top=False,
    input_shape=(64,64,3),
    alpha=0.35  # Para que sea más ligero
)

for layer in base_model.layers:
    layer.trainable = False

x = GlobalAveragePooling2D()(base_model.output)
x = Dense(64, activation='relu')(x)
x = Dropout(0.5)(x)
preds = Dense(num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=preds)
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()

# =============================================
# 6) DATA AUGMENTATION
# =============================================
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)
train_datagen.fit(x_train_resized)

# Para validación sin augmentations
val_datagen = ImageDataGenerator()

train_generator = train_datagen.flow(x_train_resized, y_train, batch_size=16)
val_generator   = val_datagen.flow(x_test_resized, y_test, batch_size=16)

# =============================================
# 7) CALLBACK: ModelCheckpoint
# =============================================
checkpoint = ModelCheckpoint(
    'best_model.h5',
    monitor='val_loss',
    save_best_only=True,
    verbose=1
)

# =============================================
# 8) ENTRENAMIENTO
# =============================================
epochs = 3

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=epochs,
    callbacks=[checkpoint]
)

# =============================================
# 9) EVALUACIÓN
# =============================================
model.load_weights('best_model.h5')
loss, acc = model.evaluate(val_generator)
print(f"\nTest Loss: {loss:.4f}")
print(f"Test Accuracy: {acc:.4f}")

"""#Visualizing Training Progress

Importance of Monitoring: Explain why tracking validation metrics helps identify overfitting or underfitting.

*   Plot training and validation accuracy/loss curves.

"""

# Plot training and validation curves
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'val'], loc='lower right')
plt.show()

# Plot the loss curves
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'val'], loc='upper right')
plt.show()

"""#Evaluation on the Test Set

Discuss how test set metrics provide the most unbiased assessment of model performance.
"""

# Después de cargar pesos o cargar el modelo:
model.load_weights('best_model.h5')  # o load_model('best_model.h5')

# Debes usar x_test_resized (64x64) en vez de x_test (32x32)
test_loss, test_acc = model.evaluate(x_test_resized, y_test, batch_size=32)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_acc)

best_model = load_model('best_model.h5')
test_loss, test_acc = best_model.evaluate(x_test_resized, y_test)

"""#Hyperparameter Tuning

>Exploring Learning Rates: In the provided code, we're iterating through different learning rates.
* Hint 1: A good starting range for the learning rate is often between 0.01 and 0.0001.
* Hint 2: Pay close attention to how quickly the validation loss starts to increase (if it does), which might signal a learning rate that's too high.


"""

def create_model(learning_rate=0.01):
    # ... (Code to build your model, using the learning_rate parameter)
    return model

# Basic parameter exploration
for lr in [0.01, 0.001, 0.0001]:
    model = create_model(learning_rate=lr)
    # ... (Training the model)

"""#Confusion Matrx"""

from sklearn.metrics import confusion_matrix
import seaborn as sn
import numpy as np # Make sure numpy is imported
import matplotlib.pyplot as plt # Make sure matplotlib.pyplot is imported

# Assuming 'best_model' and 'x_test_resized' are available in your environment
y_pred = best_model.predict(x_test_resized)  # Use x_test_resized instead of x_test
y_pred_classes = np.argmax(y_pred, axis=1)
# Assuming 'y_test' contains the true labels corresponding to 'x_test_resized'
# y_test might need to be converted to class labels if it's in one-hot encoded format
# e.g., y_test_classes = np.argmax(y_test, axis=1)

cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_classes)  # Convert y_test to class labels

plt.figure(figsize=(8, 6))
sn.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""#Discussion and Further Exploration

##Questions to consider:
1. How does the choice of pre-trained model (VGG16, ResNet50, etc.) affect the results?
2. Analyze the confusion matrix: Are errors more common between certain classes? What might explain this?
3. Experiment with different degrees of fine-tuning (freezing more/fewer layers of the pre-trained model).
4. If applicable to your dataset, can you collect more data for classes with higher error rates?
What are other ways to potentially improve accuracy? (e.g., ensembling models, exploring advanced augmentation strategies, class-weighted training)

Sources
towardsdatascience.com/build-your-own-deep-learning-classification-model-in-keras-511f647980d6
stackoverflow.com/questions/69997327/tensorflow-valueerror-input-0-is-incompatible-with-layer-model-expected-shape
www.influxdata.com/blog/time-series-forecasting-with-tensorflow-influxdb/
"""